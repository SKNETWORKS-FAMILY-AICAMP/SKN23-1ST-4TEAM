import time
import re
import hashlib
import mysql.connector
from datetime import datetime, date

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC


# MySQL ì—°ê²°ì •ë³´
DB = {
    "host": "127.0.0.1",
    "port": 3307,
    "user": "admin",
    "password": "vmfhwprxm",
    "database": "SKN23",
}


#  DB INSERT í•¨ìˆ˜
def insert_recall_to_db(row_data):
    conn = mysql.connector.connect(**DB)
    cur = conn.cursor()

    sql = """
        INSERT INTO fact_recall (
            recall_date, maker_name, car_name,
            prod_start_date, prod_end_date,
            fix_start_date, fix_end_date,
            target_count, remedy_method, uniq_hash
        )
        VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)
        ON DUPLICATE KEY UPDATE
            remedy_method = VALUES(remedy_method)
    """
    cur.execute(sql, row_data)
    conn.commit()
    cur.close()
    conn.close()


# Selenium ì‹œì‘
path = "chromedriver.exe"
service = webdriver.chrome.service.Service(path)
driver = webdriver.Chrome(service=service)
wait = WebDriverWait(driver, 10)
wait_detail = WebDriverWait(driver, 20)

driver.get("https://www.car.go.kr/ri/stat/list.do")
time.sleep(1)


# STEP 1: ì¡°íšŒê¹Œì§€ ìë™ í´ë¦­
driver.find_element(By.TAG_NAME, "body").send_keys(Keys.PAGE_DOWN)
time.sleep(1)

driver.find_element(By.CSS_SELECTOR, ".form-group.find").click()
time.sleep(2)

search_box = driver.find_element(By.ID, "srchwrd")
search_box.clear()
search_box.send_keys("ë³¼ë³´")
search_box.send_keys(Keys.RETURN)
time.sleep(2)

driver.find_element(By.XPATH, "//button[text()='ì¡°íšŒ']").click()
time.sleep(1)

driver.find_element(By.CSS_SELECTOR, ".uk-text-center").click()
time.sleep(1)


search_final_btn = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "#srchBtn")))
driver.execute_script("arguments[0].scrollIntoView(true);", search_final_btn)
time.sleep(0.2)
driver.execute_script("arguments[0].click();", search_final_btn)
time.sleep(2)


# ê²€ìƒ‰ì´ ì œëŒ€ë¡œ ì ìš©ëëŠ”ì§€ 1ë²ˆë§Œ ì²´í¬
try:
    first_title = wait.until(
        EC.presence_of_element_located((By.CSS_SELECTOR, "ul.board-hrznt-list li a strong"))
    ).text.strip()
    if "[ë³¼ë³´]" not in first_title:
        print(" [ê²½ê³ ] ë³¼ë³´ ê²€ìƒ‰ì´ ì ìš©ë˜ì§€ ì•Šì€ ê²ƒ ê°™ì•„ìš”. í˜„ì¬ ì²« ê¸€:", first_title)
except:
    pass


# ìœ í‹¸: ë¼ë²¨(th)ë¡œ ê°’ ë½‘ê¸° (í•µì‹¬ ìˆ˜ì • í¬ì¸íŠ¸)
def get_td_by_th(label: str) -> str:
    """table-stat ì•ˆì—ì„œ th í…ìŠ¤íŠ¸(label)ì— ëŒ€ì‘í•˜ëŠ” ì²« ë²ˆì§¸ td í…ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜´"""
    try:
        el = driver.find_element(
            By.XPATH,
            f"//table[contains(@class,'table-stat')]//th[normalize-space()='{label}']/following-sibling::td[1]"
        )
        return el.text.strip()
    except:
        return ""


def parse_date_str(s: str):
    """YYYY-MM-DD -> date, ì•„ë‹ˆë©´ None"""
    s = (s or "").strip()
    if not s:
        return None
    try:
        return datetime.strptime(s, "%Y-%m-%d").date()
    except:
        return None


def split_period_to_dates(period_text: str):
    """
    'YYYY-MM-DD ~ YYYY-MM-DD' / 'YYYY-MM-DD ~' / '' ë“± ì²˜ë¦¬
    -> (start_date, end_date) as date or None
    """
    txt = (period_text or "").strip()
    if not txt:
        return None, None

    # í…ìŠ¤íŠ¸ì—ì„œ ë‚ ì§œ íŒ¨í„´ë§Œ ë½‘ê¸°
    dates = re.findall(r"\d{4}-\d{2}-\d{2}", txt)
    if len(dates) == 0:
        return None, None
    if len(dates) == 1:
        return parse_date_str(dates[0]), None
    return parse_date_str(dates[0]), parse_date_str(dates[1])


def parse_target_count(txt: str):
    """'85,355 ëŒ€' -> 85355, ì—†ìœ¼ë©´ None"""
    t = (txt or "").strip()
    if not t:
        return None
    digits = re.sub(r"[^\d]", "", t)  # ìˆ«ìë§Œ
    return int(digits) if digits else None


def clean_remedy_method(txt: str):
    """
    ì‹œì •ë°©ë²•ì—ì„œ '<ë‹¨, ... ê³ ê°ì„¼í„° ...>' ì•ˆë‚´ ë¬¸êµ¬ ì œê±°
    - ê³ ê°ì„¼í„°/ë¬¸ì˜ ë¬¸ì¥ì´ í¬í•¨ëœ ì¤„ ì œê±°
    - '<ë‹¨' ë˜ëŠ” 'ë‹¨,'ìœ¼ë¡œ ì‹œì‘í•˜ëŠ” ì•ˆë‚´ ë¬¸êµ¬ ì œê±°
    """
    t = (txt or "").strip()
    if not t:
        return ""

    lines = [ln.strip() for ln in t.splitlines()]
    cleaned = []
    for ln in lines:
        if not ln:
            continue

        # '<ë‹¨' / 'ë‹¨,'ë¡œ ì‹œì‘í•˜ëŠ” ì•ˆë‚´ë¬¸ ë¼ì¸ ì œê±°
        if ln.startswith("<ë‹¨") or ln.startswith("ë‹¨,") or ln.startswith("â€»"):
            continue

        # ê³ ê°ì„¼í„° ì•ˆë‚´ ë¬¸êµ¬ ì œê±°
        if ("ê³ ê°ì„¼í„°" in ln and ("ë¬¸ì˜" in ln or "ë¬¸ì˜í•˜ì—¬" in ln or "ë¬¸ì˜í•´" in ln)):
            continue

        cleaned.append(ln)

    # ê·¸ë˜ë„ ë³¸ë¬¸ ì¤‘ê°„ì— '<ë‹¨,' ë¬¸êµ¬ê°€ ë¶™ì–´ ë“¤ì–´ì˜¤ë©´ ê·¸ ì§€ì ì—ì„œ ì˜ë¼ëƒ„
    result = "\n".join(cleaned).strip()
    cut_keywords = ["<ë‹¨", "\n<ë‹¨", "ë‹¨, ì¼ë¶€ ì°¨ëŸ‰", "ì œì‘ì‚¬ ê³ ê°ì„¼í„°"]
    cut_pos = None
    for kw in cut_keywords:
        p = result.find(kw)
        if p != -1:
            cut_pos = p if cut_pos is None else min(cut_pos, p)
    if cut_pos is not None:
        result = result[:cut_pos].strip()

    return result


#ìƒì„¸ ì •ë³´ í¬ë¡¤ë§ í•¨ìˆ˜
def crawl_detail_page():
    # ìƒì„¸ í˜ì´ì§€ë¡œ ì‹¤ì œ ì´ë™í–ˆëŠ”ì§€ ê¸°ë‹¤ë¦¼
    wait_detail.until(EC.presence_of_element_located((By.CSS_SELECTOR, "div.stat-tit div.subject")))

    # ìƒë‹¨ ì •ë³´
    title = driver.find_element(By.CSS_SELECTOR, "div.stat-tit div.subject").text.strip()
    info_list = driver.find_elements(By.CSS_SELECTOR, "div.stat-tit div.info dd")

    source = info_list[0].text.strip() if len(info_list) > 0 else ""
    write_date_text = info_list[1].text.strip() if len(info_list) > 1 else ""

    # í…Œì´ë¸”ì—ì„œ ë¼ë²¨ ê¸°ë°˜ìœ¼ë¡œ ì•ˆì • ì¶”ì¶œ (í•µì‹¬)
    maker_name = get_td_by_th("ì œì‘(ìˆ˜ì…)ì‚¬")
    car_name = get_td_by_th("ì°¨ëª…")
    prod_period = get_td_by_th("ìƒì‚°ê¸°ê°„")
    fix_period = get_td_by_th("ì‹œì •ê¸°ê°„")
    target_cnt_text = get_td_by_th("ëŒ€ìƒìˆ˜ëŸ‰")
    remedy_raw = get_td_by_th("ì‹œì •ë°©ë²•")

    # ìš”êµ¬ì‚¬í•­: ê¸°ê°„ ë¶„ë¦¬ ì €ì¥
    prod_start_date, prod_end_date = split_period_to_dates(prod_period)
    fix_start_date, fix_end_date = split_period_to_dates(fix_period)

    # ìš”êµ¬ì‚¬í•­: ëŒ€ìƒìˆ˜ëŸ‰ ìˆ«ìë§Œ
    target_count = parse_target_count(target_cnt_text)

    # ìš”êµ¬ì‚¬í•­: ì‹œì •ë°©ë²• ì•ˆë‚´ë¬¸ ì œê±°
    remedy_method = clean_remedy_method(remedy_raw)

    # recall_date (ì‘ì„±ì¼) DATE ë³€í™˜
    recall_date = parse_date_str(write_date_text)

    # í•„ìˆ˜ê°’ ì²´í¬ (NOT NULL ì»¬ëŸ¼)
    if not recall_date or not maker_name or not car_name:
        print("[ì €ì¥ ìŠ¤í‚µ] í•„ìˆ˜ê°’ ëˆ„ë½",
            f"(recall_date={write_date_text}, maker='{maker_name}', car='{car_name}')",
            " / ì œëª©:", title)
        return

    # uniq_hash (ì¤‘ë³µë°©ì§€) - í•„ìˆ˜ê°’ ìœ„ì£¼ë¡œ ì•ˆì • ìƒì„±
    hash_input = f"{recall_date.isoformat()}|{maker_name}|{car_name}|{prod_period}|{fix_period}|{target_cnt_text}"
    uniq_hash = hashlib.sha256(hash_input.encode("utf-8")).hexdigest()

    # DB insert row
    row_data = (
        recall_date,              # DATE
        maker_name,               # VARCHAR
        car_name,                 # VARCHAR
        prod_start_date,          # DATE or None
        prod_end_date,            # DATE or None
        fix_start_date,           # DATE or None
        fix_end_date,             # DATE or None
        target_count,             # INT or None
        remedy_method,            # TEXT
        uniq_hash                 # CHAR(64)
    )

    insert_recall_to_db(row_data)
    print("âœ” DB ì €ì¥ ì™„ë£Œ:", title)


# ë§í¬ í´ë¦­ ì•ˆì •í™” (Timeout ìµœì†Œí™”ìš©, íë¦„ì€ ë™ì¼)
def open_detail_from_link(link):
    driver.execute_script("arguments[0].scrollIntoView({block:'center'});", link)
    time.sleep(0.1)
    try:
        link.click()
    except:
        driver.execute_script("arguments[0].click();", link)

    # ìƒì„¸ ì§„ì… í™•ì¸
    wait_detail.until(EC.presence_of_element_located((By.CSS_SELECTOR, "div.stat-tit div.subject")))


# í˜ì´ì§€ ìˆœì°¨ ì´ë™ (1~10)
for page in range(1, 11):

    print(f"\n========== {page} í˜ì´ì§€ ==========")

    # í˜ì´ì§€ë„¤ì´ì…˜ ì˜ì—­ê¹Œì§€ ìŠ¤í¬ë¡¤
    pagination = wait.until(
        EC.presence_of_element_located(
            (By.CSS_SELECTOR, "ul.uk-pagination")
        )
    )
    driver.execute_script("arguments[0].scrollIntoView(true);", pagination)
    time.sleep(0.5)

    # í˜ì´ì§€ ë²„íŠ¼ í´ë¦­ ì‹œë„
    try:
        page_btn = wait.until(
            EC.element_to_be_clickable(
                (By.XPATH, f"//ul[contains(@class,'pagination')]//a[text()='{page}']")
            )
        )
        driver.execute_script("arguments[0].click();", page_btn)
        time.sleep(1.5)
    except:
        # 1í˜ì´ì§€ëŠ” spanì¼ ìˆ˜ ìˆìŒ -> "skip"ì€ í•˜ë˜, ì‹¤ì œ ìˆ˜ì§‘ì€ í˜„ì¬ í˜ì´ì§€ì—ì„œ ì§„í–‰ ê°€ëŠ¥
        if page == 1:
            print("â„¹ 1í˜ì´ì§€ëŠ” span(í˜„ì¬í˜ì´ì§€)ì´ë¼ í´ë¦­ ì—†ì´ ì§„í–‰")
        else:
            print(f"âš  {page} í˜ì´ì§€ëŠ” í´ë¦­í•  a íƒœê·¸ê°€ ì—†ì–´ span ìƒíƒœì¼ ìˆ˜ ìˆìŒ. skip")
            continue

    # ê¸€ 5ê°œ ìˆ˜ì§‘
    links = wait.until(
        EC.presence_of_all_elements_located(
            (By.CSS_SELECTOR, "ul.board-hrznt-list li a")
        )
    )

    for i in range(len(links)):
        links = driver.find_elements(By.CSS_SELECTOR, "ul.board-hrznt-list li a")
        link = links[i]

        print(f"â–¶ {page}í˜ì´ì§€ - {i+1}ë²ˆì§¸ê¸€:", link.text.strip())

        open_detail_from_link(link)   # (ê¸°ì¡´ link.click() ëŒ€ì‹  ìµœì†Œ ì•ˆì •í™”)
        crawl_detail_page()

        driver.back()
        wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, "ul.board-hrznt-list li a")))
        time.sleep(0.7)


print("\nğŸ‰ ëª¨ë“  í˜ì´ì§€ í¬ë¡¤ë§ ë° DB ì €ì¥ ì™„ë£Œ!")
